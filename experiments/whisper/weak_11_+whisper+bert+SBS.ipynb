{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f28df6c-fac3-47e8-8457-ee62321f061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import whisper\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb808b6-c3f8-4f50-9319-842844d3cffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12fb6341-8550-49ee-9cbe-7f2c0b53899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load and Unfreeze Whisper‑medium and BERT ---\n",
    "whisper_model = whisper.load_model(\"base.en\").to(device)\n",
    "for param in whisper_model.parameters():\n",
    "    param.requires_grad = True\n",
    "whisper_model.train()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\").to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a74f2f2-029d-436d-bd96-c8c4795a0dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: rtfiof (rtfiof-hse-university). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>F:\\Project\\att_2\\wandb\\run-20250403_210202-8uxchcyg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rtfiof-hse-university/somos-ensemble2-ssl-sbs/runs/8uxchcyg' target=\"_blank\">finetune-whisper_b+bert+sbs</a></strong> to <a href='https://wandb.ai/rtfiof-hse-university/somos-ensemble2-ssl-sbs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rtfiof-hse-university/somos-ensemble2-ssl-sbs' target=\"_blank\">https://wandb.ai/rtfiof-hse-university/somos-ensemble2-ssl-sbs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rtfiof-hse-university/somos-ensemble2-ssl-sbs/runs/8uxchcyg' target=\"_blank\">https://wandb.ai/rtfiof-hse-university/somos-ensemble2-ssl-sbs/runs/8uxchcyg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B online. Running your script from this directory will now sync to the cloud.\n"
     ]
    }
   ],
   "source": [
    "# --- Initialize wandb ---\n",
    "wandb.init(project=\"somos-ensemble2-ssl-sbs\", name=\"finetune-whisper_b+bert+sbs\")\n",
    "!wandb online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f8be53f-d3ba-4604-a7c2-020dab6cd4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SBS Dataset with Optional Subsetting ---\n",
    "class SBSDataset(Dataset):\n",
    "    def __init__(self, csv_file, base_dir, subset=False, is_test=False):\n",
    "        \"\"\"\n",
    "        csv_file: Path to train or test CSV file.\n",
    "        base_dir: Base directory for audio files.\n",
    "        subset: If True, only 0.1% of the data is used.\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "\n",
    "        if subset:\n",
    "            self.df = self.df.sample(frac=0.05, random_state=42).reset_index(drop=True)\n",
    "            # self.df = self.df.sample(frac=0.001, random_state=42).reset_index(drop=True)\n",
    "\n",
    "        self.base_dir = base_dir\n",
    "        self.is_test = is_test\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        pair = row[\"utterance_pairs\"]\n",
    "        audio1_name, audio2_name = pair.split(\"+\")\n",
    "        audio1_path = os.path.join(self.base_dir, audio1_name)\n",
    "        audio2_path = os.path.join(self.base_dir, audio2_name)\n",
    "        \n",
    "        text_column = \"right_text\" if not self.is_test else \"text\"\n",
    "        text = row[text_column]\n",
    "        \n",
    "        sbs1 = float(row[\"SBS_1\"])\n",
    "        sbs2 = float(row[\"SBS_2\"])\n",
    "        return audio1_path, audio2_path, text, sbs1, sbs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c739af4e-420c-436e-9ec2-0f0b62a5c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Collate Function for SBS ---\n",
    "def collate_fn_sbs(batch):\n",
    "    audio1_paths, audio2_paths, texts, sbs1_list, sbs2_list = zip(*batch)\n",
    "    \n",
    "    # Process first audio of each pair.\n",
    "    audios1 = [whisper.load_audio(path) for path in audio1_paths]\n",
    "    audios1 = [whisper.pad_or_trim(audio) for audio in audios1]\n",
    "    mels1 = [whisper.log_mel_spectrogram(audio).to(device) for audio in audios1]\n",
    "    mels1 = torch.stack(mels1)\n",
    "    # Get audio embeddings (mean-pooled over time).\n",
    "    audio1_emb = whisper_model.encoder(mels1).mean(dim=1)\n",
    "    \n",
    "    # Process second audio of each pair.\n",
    "    audios2 = [whisper.load_audio(path) for path in audio2_paths]\n",
    "    audios2 = [whisper.pad_or_trim(audio) for audio in audios2]\n",
    "    mels2 = [whisper.log_mel_spectrogram(audio).to(device) for audio in audios2]\n",
    "    mels2 = torch.stack(mels2)\n",
    "    audio2_emb = whisper_model.encoder(mels2).mean(dim=1)\n",
    "    \n",
    "    # Process the text once per pair.\n",
    "    inputs = tokenizer(list(texts), return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        text_emb = bert_model(**inputs).last_hidden_state[:, 0, :]\n",
    "        \n",
    "    sbs1_tensor = torch.tensor(sbs1_list, dtype=torch.float).to(device)\n",
    "    sbs2_tensor = torch.tensor(sbs2_list, dtype=torch.float).to(device)\n",
    "    \n",
    "    return audio1_emb, audio2_emb, text_emb, sbs1_tensor, sbs2_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc5bea04-6474-410e-83ee-e22349e87cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Weak Learners (same as before) ---\n",
    "class WeakLearners(nn.Module):\n",
    "    def __init__(self, audio_dim, text_dim, device=\"cuda\"):\n",
    "        super(WeakLearners, self).__init__()\n",
    "        self.audio_dim = audio_dim\n",
    "        self.text_dim = text_dim\n",
    "        self.device = device\n",
    "\n",
    "        self.ridge_regressor = Ridge(alpha=1.0)\n",
    "        self.svr = SVR()\n",
    "        self.dtr = DecisionTreeRegressor()\n",
    "\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, train_loader):\n",
    "        print(\"Fitting weak learners on SBS data...\")\n",
    "        all_audio_emb, all_text_emb, all_labels = [], [], []\n",
    "        # For each pair in the batch, treat the first and second audio separately.\n",
    "        for audio1_emb, audio2_emb, text_emb, sbs1, sbs2 in tqdm(train_loader, desc=\"Extracting embeddings\", unit=\"batch\"):\n",
    "            # Convert to numpy arrays.\n",
    "            audio1_np = audio1_emb.cpu().detach().numpy()\n",
    "            audio2_np = audio2_emb.cpu().detach().numpy()\n",
    "            text_np = text_emb.cpu().detach().numpy()\n",
    "            sbs1_np = sbs1.cpu().detach().numpy()\n",
    "            sbs2_np = sbs2.cpu().detach().numpy()\n",
    "            \n",
    "            # Append first audio example.\n",
    "            all_audio_emb.append(audio1_np)\n",
    "            all_text_emb.append(text_np)\n",
    "            all_labels.append(sbs1_np)\n",
    "            \n",
    "            # Append second audio example.\n",
    "            all_audio_emb.append(audio2_np)\n",
    "            all_text_emb.append(text_np)\n",
    "            all_labels.append(sbs2_np)\n",
    "        \n",
    "        all_audio_emb = np.vstack(all_audio_emb)\n",
    "        all_text_emb = np.vstack(all_text_emb)\n",
    "        all_labels = np.hstack(all_labels)\n",
    "        \n",
    "        # Combine audio and text embeddings.\n",
    "        combined_embeddings = np.hstack((all_audio_emb, all_text_emb))\n",
    "        \n",
    "        # Train each weak learner.\n",
    "        for model, name in zip([self.ridge_regressor, self.svr, self.dtr],\n",
    "                               [\"Ridge Regression\", \"SVR\", \"Decision Tree\"]):\n",
    "            print(f\"Training {name}...\")\n",
    "            model.fit(combined_embeddings, all_labels)\n",
    "        self.fitted = True\n",
    "        print(\"Weak learners training completed.\")\n",
    "\n",
    "    def forward(self, audio_emb, text_emb):\n",
    "        if not self.fitted:\n",
    "            raise RuntimeError(\"Weak learners have not been fitted. Call 'fit()' before using the model.\")\n",
    "        # Concatenate audio and text embeddings.\n",
    "        combined = torch.cat([audio_emb, text_emb], dim=1).cpu().detach().numpy()\n",
    "        with torch.no_grad():\n",
    "            ridge_pred = self.ridge_regressor.predict(combined)\n",
    "            svr_pred = self.svr.predict(combined)\n",
    "            dtr_pred = self.dtr.predict(combined)\n",
    "        # Convert predictions to tensors.\n",
    "        ridge_pred = torch.from_numpy(ridge_pred).float().to(self.device)\n",
    "        svr_pred = torch.from_numpy(svr_pred).float().to(self.device)\n",
    "        dtr_pred = torch.from_numpy(dtr_pred).float().to(self.device)\n",
    "        return ridge_pred, svr_pred, dtr_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2989e82a-737e-487d-b61e-e54711e6a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Stacking Meta-Learner ---\n",
    "class StackingMetaLearner(nn.Module):\n",
    "    def __init__(self, weak_output_dim=3, hidden_dim=256):\n",
    "        super(StackingMetaLearner, self).__init__()\n",
    "        self.fc1 = nn.Linear(weak_output_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, weak_outputs):\n",
    "        x = F.relu(self.fc1(weak_outputs))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "536b769d-7464-46ac-af99-47d588a7a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SSLEnsembleModel (Ensemble using weak learners and meta-learner) ---\n",
    "class SSLEnsembleModel(nn.Module):\n",
    "    def __init__(self, audio_dim, text_dim, hidden_dim, weak_learners):\n",
    "        super(SSLEnsembleModel, self).__init__()\n",
    "        if weak_learners is None:\n",
    "            raise ValueError(\"Weak learners must be provided and fitted before initializing SSLEnsembleModel.\")\n",
    "        self.weak_learners = weak_learners\n",
    "        self.stacking_meta_learner = StackingMetaLearner(weak_output_dim=3, hidden_dim=hidden_dim)\n",
    "\n",
    "    def forward(self, audio_emb, text_emb):\n",
    "        if not self.weak_learners.fitted:\n",
    "            raise RuntimeError(\"Weak learners have not been fitted. Call 'fit()' before using the model.\")\n",
    "        # Get predictions from the weak learners.\n",
    "        ridge_pred, svr_pred, dtr_pred = self.weak_learners(audio_emb, text_emb)\n",
    "        # Stack the predictions into one tensor.\n",
    "        weak_outputs = torch.stack([ridge_pred, svr_pred, dtr_pred], dim=1)\n",
    "        # Meta-learner produces the final output.\n",
    "        final_output = self.stacking_meta_learner(weak_outputs)\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9695effb-a8c8-4291-9e94-6de6e9b36637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Function with Intermediate Evaluation ---\n",
    "def train_meta_learner(train_loader, test_loader, ensemble_model, optimizer, criterion, epochs=20, eval_interval=15000):\n",
    "    ensemble_model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        total_mse = 0.0\n",
    "        total_mae = 0.0\n",
    "        batch_count = 0\n",
    "\n",
    "        for batch_idx, (audio1_emb, audio2_emb, text_emb, sbs1, sbs2) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}\")):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            pred1 = ensemble_model(audio1_emb, text_emb).squeeze()\n",
    "            pred2 = ensemble_model(audio2_emb, text_emb).squeeze()\n",
    "\n",
    "            # Compute loss\n",
    "            loss1 = criterion(pred1, sbs1)\n",
    "            loss2 = criterion(pred2, sbs2)\n",
    "            loss = loss1 + loss2\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_count += 1\n",
    "\n",
    "            # Convert to CPU for logging and ensure arrays\n",
    "            pred1_cpu = np.atleast_1d(pred1.detach().cpu().numpy())\n",
    "            pred2_cpu = np.atleast_1d(pred2.detach().cpu().numpy())\n",
    "            sbs1_cpu = np.atleast_1d(sbs1.cpu().numpy())\n",
    "            sbs2_cpu = np.atleast_1d(sbs2.cpu().numpy())\n",
    "\n",
    "            # Compute evaluation metrics\n",
    "            total_mse += (mean_squared_error(sbs1_cpu, pred1_cpu) + mean_squared_error(sbs2_cpu, pred2_cpu))\n",
    "            total_mae += (mean_absolute_error(sbs1_cpu, pred1_cpu) + mean_absolute_error(sbs2_cpu, pred2_cpu))\n",
    "\n",
    "            # Log every 10,000 batches\n",
    "            if (batch_idx + 1) % eval_interval == 0:\n",
    "                print(f\"Evaluating at batch {batch_idx+1}...\")\n",
    "                evaluate(test_loader, ensemble_model, criterion)\n",
    "\n",
    "        # Compute epoch-level metrics\n",
    "        avg_loss = total_loss / (2 * batch_count)\n",
    "        avg_mse = total_mse / (2 * batch_count)\n",
    "        avg_mae = total_mae / (2 * batch_count)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Loss={avg_loss:.4f}, MSE={avg_mse:.4f}, MAE={avg_mae:.4f}\")\n",
    "\n",
    "        # Log metrics to Weights & Biases\n",
    "        wandb.log({\"epoch_loss\": avg_loss, \"epoch_mse\": avg_mse, \"epoch_mae\": avg_mae})\n",
    "\n",
    "        # Evaluate at the end of each epoch\n",
    "        evaluate(test_loader, ensemble_model, criterion)\n",
    "\n",
    "\n",
    "# --- Evaluation Function ---\n",
    "def evaluate(test_loader, ensemble_model, criterion):\n",
    "    ensemble_model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_mse = 0.0\n",
    "    total_mae = 0.0\n",
    "    correct_order = 0\n",
    "    total_samples = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for audio1_emb, audio2_emb, text_emb, sbs1, sbs2 in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            pred1 = ensemble_model(audio1_emb, text_emb).squeeze()\n",
    "            pred2 = ensemble_model(audio2_emb, text_emb).squeeze()\n",
    "\n",
    "            loss1 = criterion(pred1, sbs1)\n",
    "            loss2 = criterion(pred2, sbs2)\n",
    "            total_loss += (loss1.item() + loss2.item())\n",
    "            batch_count += 1\n",
    "\n",
    "            # Convert to CPU for logging\n",
    "            pred1_cpu = pred1.cpu().numpy()\n",
    "            pred2_cpu = pred2.cpu().numpy()\n",
    "            sbs1_cpu = sbs1.cpu().numpy()\n",
    "            sbs2_cpu = sbs2.cpu().numpy()\n",
    "\n",
    "            total_mse += (mean_squared_error(sbs1_cpu, pred1_cpu) + mean_squared_error(sbs2_cpu, pred2_cpu))\n",
    "            total_mae += (mean_absolute_error(sbs1_cpu, pred1_cpu) + mean_absolute_error(sbs2_cpu, pred2_cpu))\n",
    "\n",
    "            # Compute Ranking Accuracy (Did the model preserve the SBS order?)\n",
    "            correct_order += np.sum((sbs1_cpu > sbs2_cpu) == (pred1_cpu > pred2_cpu))\n",
    "            total_samples += len(sbs1_cpu)\n",
    "\n",
    "    avg_loss = total_loss / (2 * batch_count)\n",
    "    avg_mse = total_mse / (2 * batch_count)\n",
    "    avg_mae = total_mae / (2 * batch_count)\n",
    "    accuracy = correct_order / total_samples if total_samples > 0 else 0\n",
    "\n",
    "    print(f\"Test Loss: {avg_loss}, Test MSE: {avg_mse}, Test MAE: {avg_mae}, Ranking Accuracy: {accuracy:.4f}\")\n",
    "    wandb.log({\"test_loss\": avg_loss, \"test_mse\": avg_mse, \"test_mae\": avg_mae, \"test_ranking_accuracy\": accuracy})\n",
    "\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb794d82-5527-41dd-996b-6850cfd84b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q\\AppData\\Local\\Temp\\ipykernel_124688\\808334554.py:9: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.df = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting weak learners on SBS data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|████████████████████████████████████████████████████| 5516/5516 [42:06<00:00,  2.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Ridge Regression...\n",
      "Training SVR...\n",
      "Training Decision Tree...\n",
      "Weak learners training completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████████████████████████████████████████████████| 5516/5516 [56:01<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.0218, MSE=0.0218, MAE=0.1009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████| 279/279 [02:32<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.017345284500057512, Test MSE: 0.017345284524884437, Test MAE: 0.10342563135970023, Ranking Accuracy: 0.6601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████████████████████████████████████████████| 5516/5516 [51:03<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss=0.0006, MSE=0.0006, MAE=0.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████| 279/279 [02:33<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.027922636265703727, Test MSE: 0.027922636285210595, Test MAE: 0.13203397735045375, Ranking Accuracy: 0.6224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████████████████████████████████████████████████████████████████████| 5516/5516 [51:07<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss=0.0000, MSE=0.0000, MAE=0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████| 279/279 [02:32<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.028601116681363815, Test MSE: 0.028601116614289396, Test MAE: 0.13354185921904435, Ranking Accuracy: 0.6170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|█████████████████████████████████████████████████████████████████████| 5516/5516 [51:39<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss=0.0000, MSE=0.0000, MAE=0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████| 279/279 [02:36<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.028696632017106097, Test MSE: 0.02869663206446502, Test MAE: 0.13369071678555566, Ranking Accuracy: 0.6152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|█████████████████████████████████████████████████████████████████████| 5516/5516 [51:46<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss=0.0000, MSE=0.0000, MAE=0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████| 279/279 [02:35<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.02877441626296656, Test MSE: 0.02877441645302813, Test MAE: 0.1338269326395245, Ranking Accuracy: 0.6152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|█████████████████████████████████████████████████████████████████████| 5516/5516 [51:34<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss=0.0000, MSE=0.0000, MAE=0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████| 279/279 [02:34<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.02878492496818835, Test MSE: 0.02878492483602149, Test MAE: 0.1338339300966391, Ranking Accuracy: 0.6126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|█████████████████████████████████████████████████████████████████████| 5516/5516 [52:59<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss=0.0000, MSE=0.0000, MAE=0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████| 279/279 [02:45<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.028820715716532615, Test MSE: 0.0288207155959447, Test MAE: 0.13390644950838926, Ranking Accuracy: 0.6117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|█████████████████████████████████████████████████████████████████████| 5516/5516 [52:02<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss=0.0000, MSE=0.0000, MAE=0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████| 279/279 [02:43<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.028811607783782132, Test MSE: 0.02881160786535631, Test MAE: 0.133866140331846, Ranking Accuracy: 0.6126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|█████████████████████████████████████████████████████████████████████| 5516/5516 [52:45<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss=0.0000, MSE=0.0000, MAE=0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████| 279/279 [02:33<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0288486123362708, Test MSE: 0.028848612292145637, Test MAE: 0.13393767486496638, Ranking Accuracy: 0.6108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|████████████████████████████████████████████████████████████████████| 5516/5516 [51:50<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss=0.0000, MSE=0.0000, MAE=0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████| 279/279 [02:39<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.028874631091955663, Test MSE: 0.028874631106559735, Test MAE: 0.13399130833672365, Ranking Accuracy: 0.6108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11:   2%|█▏                                                                    | 89/5516 [00:51<52:13,  1.73it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(ensemble_model\u001b[38;5;241m.\u001b[39mstacking_meta_learner\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[0;32m     25\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m---> 26\u001b[0m \u001b[43mtrain_meta_learner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensemble_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Evaluate on the test set.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m evaluate(test_loader, ensemble_model, criterion)\n",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m, in \u001b[0;36mtrain_meta_learner\u001b[1;34m(train_loader, test_loader, ensemble_model, optimizer, criterion, epochs, eval_interval)\u001b[0m\n\u001b[0;32m      8\u001b[0m total_mae \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m      9\u001b[0m batch_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 11\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio1_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio2_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msbs1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msbs2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEpoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Forward pass\u001b[39;49;00m\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m, in \u001b[0;36mcollate_fn_sbs\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      3\u001b[0m audio1_paths, audio2_paths, texts, sbs1_list, sbs2_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Process first audio of each pair.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m audios1 \u001b[38;5;241m=\u001b[39m [\u001b[43mwhisper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m audio1_paths]\n\u001b[0;32m      7\u001b[0m audios1 \u001b[38;5;241m=\u001b[39m [whisper\u001b[38;5;241m.\u001b[39mpad_or_trim(audio) \u001b[38;5;28;01mfor\u001b[39;00m audio \u001b[38;5;129;01min\u001b[39;00m audios1]\n\u001b[0;32m      8\u001b[0m mels1 \u001b[38;5;241m=\u001b[39m [whisper\u001b[38;5;241m.\u001b[39mlog_mel_spectrogram(audio)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m audio \u001b[38;5;129;01min\u001b[39;00m audios1]\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\whisper\\audio.py:58\u001b[0m, in \u001b[0;36mload_audio\u001b[1;34m(file, sr)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# fmt: on\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstdout\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load audio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mdecode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda\\envs\\project\\Lib\\subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m    546\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m--> 548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda\\envs\\project\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1034\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda\\envs\\project\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1540\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1544\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1554\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1555\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- Main Script ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the base directory to prepend to the audio filenames.\n",
    "    base_audio_dir = \"archive/update_SOMOS_v2/update_SOMOS_v2/all_audios/all_wavs\"\n",
    "\n",
    "    subset = True\n",
    "    # subset = False\n",
    "    \n",
    "    # Create datasets and dataloaders for training and testing.\n",
    "    train_dataset = SBSDataset(\"archive/train_same_pairs_text.csv\", base_dir=base_audio_dir, subset=subset, is_test=False)\n",
    "    test_dataset = SBSDataset(\"archive/test_same_pairs_text.csv\", base_dir=base_audio_dir, subset=subset, is_test=True)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn_sbs)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn_sbs)\n",
    "    \n",
    "    # Initialize and fit weak learners.\n",
    "    weak_learners = WeakLearners(audio_dim=512, text_dim=768, device=device)\n",
    "    weak_learners.fit(train_loader)\n",
    "    \n",
    "    # Initialize the ensemble model (which uses the fitted weak learners).\n",
    "    ensemble_model = SSLEnsembleModel(audio_dim=512, text_dim=768, hidden_dim=256, weak_learners=weak_learners).to(device)\n",
    "    \n",
    "    # Train the stacking meta-learner.\n",
    "    optimizer = torch.optim.Adam(ensemble_model.stacking_meta_learner.parameters(), lr=1e-5)\n",
    "    criterion = nn.MSELoss()\n",
    "    train_meta_learner(train_loader, test_loader, ensemble_model, optimizer, criterion, epochs=20)\n",
    "\n",
    "    \n",
    "    # Evaluate on the test set.\n",
    "    evaluate(test_loader, ensemble_model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab8af55-7275-48db-b4d6-cfcd5851a681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759aeb36-d489-4a14-96c4-2015cd563c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b50520-d734-48e1-8b86-4df4c79f6829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307a3078-8847-47fb-bd64-ed3b60f73cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ccbae-827a-46f6-b571-15eb5c400df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d58aa0-3f2d-4dfb-9a98-7f25e8a52fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e3943-87a3-492e-9dbf-a19b8e5b8d39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
