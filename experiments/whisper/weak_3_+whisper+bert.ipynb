{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f28df6c-fac3-47e8-8457-ee62321f061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from transformers import Wav2Vec2Model, HubertModel, WavLMModel\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import wandb\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from whisper import load_model\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb808b6-c3f8-4f50-9319-842844d3cffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12fb6341-8550-49ee-9cbe-7f2c0b53899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_model = whisper.load_model(\"base.en\").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = AutoModel.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a74f2f2-029d-436d-bd96-c8c4795a0dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: rtfiof (rtfiof-hse-university). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>F:\\Project\\att_2\\wandb\\run-20250320_194031-l0imd9gz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rtfiof-hse-university/somos-ensemble2-ssl/runs/l0imd9gz' target=\"_blank\">finetune-whisper+bert</a></strong> to <a href='https://wandb.ai/rtfiof-hse-university/somos-ensemble2-ssl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rtfiof-hse-university/somos-ensemble2-ssl' target=\"_blank\">https://wandb.ai/rtfiof-hse-university/somos-ensemble2-ssl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rtfiof-hse-university/somos-ensemble2-ssl/runs/l0imd9gz' target=\"_blank\">https://wandb.ai/rtfiof-hse-university/somos-ensemble2-ssl/runs/l0imd9gz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B online. Running your script from this directory will now sync to the cloud.\n"
     ]
    }
   ],
   "source": [
    "# --- Initialize wandb ---\n",
    "wandb.init(project=\"somos-ensemble2-ssl\", name=\"finetune-whisper+bert\")\n",
    "!wandb online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "302e5bf6-a061-469e-bd72-c1cdae6dafce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Utility Functions ---\n",
    "def load_json(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def process_audio_path(clean_path, base_dir=\"data/somos/audios\"):\n",
    "    return os.path.join(base_dir, clean_path.replace(\"\\\\\", \"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f01dabc-9bf4-4325-92c2-66e2326d6e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dataset Class ---\n",
    "class SOMOSDataset(Dataset):\n",
    "    def __init__(self, json_file, base_dir=\"data/somos/audios\"):\n",
    "        self.samples = load_json(json_file)\n",
    "        self.base_dir = base_dir\n",
    "        self.labels = [float(sample[\"mos\"]) for sample in self.samples]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        text = sample[\"text\"]\n",
    "        label = torch.tensor(float(sample[\"mos\"]), dtype=torch.float)\n",
    "        audio_path = process_audio_path(sample[\"clean path\"], self.base_dir)\n",
    "        return audio_path, text, label\n",
    "\n",
    "\n",
    "\n",
    "class AttentionPooling(torch.nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.attention = torch.nn.Linear(embed_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        weights = torch.nn.functional.softmax(self.attention(x), dim=1)  \n",
    "        return (weights * x).sum(dim=1)  \n",
    "\n",
    "\n",
    "attn_pool = AttentionPooling(embed_dim=512).to(device)  # Whisper Base uses 512-dim embeddings\n",
    "\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    audio_paths, texts, labels = zip(*batch)\n",
    "    \n",
    "    # Load and preprocess audio\n",
    "    audios = [whisper.load_audio(path) for path in audio_paths]\n",
    "    audios = [whisper.pad_or_trim(audio) for audio in audios]\n",
    "    mel_spectrograms = [whisper.log_mel_spectrogram(audio).to(device) for audio in audios]\n",
    "    mel_spectrograms = torch.stack(mel_spectrograms)  # (batch, 80, 3000)\n",
    "\n",
    "    # Compute audio embeddings with attention pooling\n",
    "    with torch.no_grad():\n",
    "        whisper_outputs = whisper_model.encoder(mel_spectrograms)  # (batch, time, embed_dim)\n",
    "        audio_embeddings = attn_pool(whisper_outputs)  \n",
    "\n",
    "    # Process texts using BERT\n",
    "    inputs = tokenizer(list(texts), return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        text_embeddings = bert_model(**inputs).last_hidden_state[:, 0, :]  # (batch, bert_embed_dim)\n",
    "\n",
    "    labels = torch.stack(labels).to(device)\n",
    "    return audio_embeddings, text_embeddings, labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46e84ffc-3b2c-47fd-9c75-6eff75740056",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeakLearners(nn.Module):\n",
    "    def __init__(self, audio_dim, text_dim, device=\"cuda:1\"):\n",
    "        super(WeakLearners, self).__init__()\n",
    "        self.audio_dim = audio_dim\n",
    "        self.text_dim = text_dim\n",
    "        self.device = device\n",
    "\n",
    "        self.ridge_regressor = Ridge(alpha=1.0)\n",
    "        self.svr = SVR()\n",
    "        self.dtr = DecisionTreeRegressor()\n",
    "\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, train_loader):\n",
    "        \"\"\" Train weak learners using train dataset embeddings \"\"\"\n",
    "        print(\"Fitting weak learners...\")\n",
    "\n",
    "        all_audio_emb, all_text_emb, all_labels = [], [], []\n",
    "\n",
    "        for audio_emb, text_emb, labels in tqdm(train_loader, desc=\"Processing embeddings\", unit=\"batch\"):\n",
    "            all_audio_emb.append(audio_emb.cpu().detach().numpy())\n",
    "            all_text_emb.append(text_emb.cpu().detach().numpy())\n",
    "            all_labels.append(labels.cpu().detach().numpy())\n",
    "\n",
    "        if not all_audio_emb or not all_text_emb or not all_labels:\n",
    "            raise RuntimeError(\"No embeddings found in the dataset! Check if the train_loader is correctly loading data.\")\n",
    "\n",
    "        all_audio_emb = np.vstack(all_audio_emb)\n",
    "        all_text_emb = np.vstack(all_text_emb)\n",
    "        all_labels = np.hstack(all_labels)\n",
    "\n",
    "        combined_embeddings = np.hstack((all_audio_emb, all_text_emb))\n",
    "\n",
    "        print(\"Training weak learners...\")\n",
    "        for model, name in zip([self.ridge_regressor, self.svr, self.dtr], \n",
    "                               [\"Ridge Regression\", \"SVR\", \"Decision Tree\"]):\n",
    "            with tqdm(total=1, desc=f\"Training {name}\", unit=\"step\") as pbar:\n",
    "                model.fit(combined_embeddings, all_labels)\n",
    "                pbar.update(1)\n",
    "\n",
    "        self.fitted = True\n",
    "        print(\"Weak learners training completed.\")\n",
    "\n",
    "    def forward(self, audio_emb, text_emb):\n",
    "        if not self.fitted:\n",
    "            raise RuntimeError(\"Weak learners have not been fitted. Call 'fit()' before using the model.\")\n",
    "\n",
    "        combined_embeddings = torch.cat([audio_emb, text_emb], dim=1).cpu().detach().numpy()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            ridge_pred = self.ridge_regressor.predict(combined_embeddings)\n",
    "            svr_pred = self.svr.predict(combined_embeddings)\n",
    "            dtr_pred = self.dtr.predict(combined_embeddings)\n",
    "\n",
    "        ridge_pred = torch.from_numpy(ridge_pred).float().to(self.device)\n",
    "        svr_pred = torch.from_numpy(svr_pred).float().to(self.device)\n",
    "        dtr_pred = torch.from_numpy(dtr_pred).float().to(self.device)\n",
    "\n",
    "        return ridge_pred, svr_pred, dtr_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ecacc4d-08b4-4ee1-8f43-6ce200e65022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Stacking Model (Meta-Learner) ---\n",
    "class StackingMetaLearner(nn.Module):\n",
    "    def __init__(self, weak_output_dim=3, hidden_dim=256):\n",
    "        super(StackingMetaLearner, self).__init__()\n",
    "        self.fc1 = nn.Linear(weak_output_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, weak_outputs):\n",
    "        x = F.relu(self.fc1(weak_outputs))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "423b5ecb-80b9-4e0c-a10c-86d6f40c5cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Model ---\n",
    "class SSLEnsembleModel(nn.Module):\n",
    "    def __init__(self, audio_dim, text_dim, hidden_dim=256, weak_learners=None):\n",
    "        super(SSLEnsembleModel, self).__init__()\n",
    "        if weak_learners is None:\n",
    "            raise ValueError(\"Weak learners must be provided and fitted before initializing SSLEnsembleModel.\")\n",
    "        \n",
    "        self.weak_learners = weak_learners\n",
    "        self.stacking_meta_learner = StackingMetaLearner(weak_output_dim=3, hidden_dim=hidden_dim)\n",
    "\n",
    "    def forward(self, audio_emb, text_emb):\n",
    "        if not self.weak_learners.fitted:\n",
    "            raise RuntimeError(\"Weak learners have not been fitted. Call 'fit()' before using the model.\")\n",
    "        \n",
    "        ridge_pred, svr_pred, dtr_pred = self.weak_learners(audio_emb, text_emb)\n",
    "\n",
    "        weak_outputs = torch.stack([ridge_pred, svr_pred, dtr_pred], dim=1)\n",
    "\n",
    "        final_output = self.stacking_meta_learner(weak_outputs)\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73fc2793-3189-44df-87b4-d216b1a84d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "\n",
    "def evaluate(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_pbar = tqdm(test_loader, desc=\"Evaluation\", leave=False)\n",
    "        for audio_emb, text_emb, labels in test_pbar:\n",
    "            audio_emb, text_emb, labels = audio_emb.to(device), text_emb.to(device), labels.to(device)\n",
    "            outputs = model(audio_emb, text_emb)\n",
    "            preds = outputs.squeeze()\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            test_pbar.set_postfix({\"predicted\": preds[:5].cpu().numpy(), \"ground_truth\": labels[:5].cpu().numpy()})\n",
    "\n",
    "    # Convert lists to numpy arrays for easier calculation\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Accuracy (up to ±0.5)\n",
    "    accuracy = np.mean(np.abs(all_preds - all_labels) <= 0.5)\n",
    "\n",
    "    # MSE and RMSE\n",
    "    mse = mean_squared_error(all_labels, all_preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # LCC (Linear Correlation Coefficient)\n",
    "    lcc = np.corrcoef(all_labels, all_preds)[0, 1]\n",
    "\n",
    "    # KTAU (Kendall's Tau)\n",
    "    k_tau, _ = kendalltau(all_labels, all_preds)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Accuracy (±0.5): {accuracy*100:.2f}%\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"LCC: {lcc:.4f}\")\n",
    "    print(f\"KTAU: {k_tau:.4f}\")\n",
    "\n",
    "    # Show 30 examples of predicted and ground truth MOS\n",
    "    print(\"\\n5 Examples of Predicted and Ground Truth MOS:\")\n",
    "    for i in range(5):\n",
    "        print(f\"Pred: {all_preds[i]:.2f}, GT: {all_labels[i]:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "246a2b72-6b7c-46d8-b3f5-c50e495e5086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Training Loop ---\n",
    "def main():\n",
    "    train_json = \"data/somos/audios/train_new.json\"\n",
    "    test_json = \"data/somos/audios/test_new.json\"\n",
    "\n",
    "    train_dataset = SOMOSDataset(train_json)\n",
    "    test_dataset = SOMOSDataset(test_json)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    dummy_audio, dummy_text, _ = next(iter(train_loader))\n",
    "    audio_dim, text_dim = dummy_audio.shape[1], dummy_text.shape[1]\n",
    "    \n",
    "    weak_learners = WeakLearners(audio_dim, text_dim).to(device)\n",
    "    weak_learners.fit(train_loader)\n",
    "    \n",
    "    model = SSLEnsembleModel(audio_dim, text_dim, hidden_dim=256, weak_learners=weak_learners).to(device)\n",
    "\n",
    "    wandb.watch(model, log=\"all\", log_freq=100)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    num_epochs = 20\n",
    "    best_mse = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss, total_samples = 0.0, 0\n",
    "\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\", leave=False)\n",
    "        for audio_emb, text_emb, labels in train_pbar:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(audio_emb, text_emb)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * audio_emb.size(0)\n",
    "            total_samples += labels.size(0)\n",
    "            wandb.log({\"train_loss\": loss.item()})\n",
    "            train_pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        train_mse = running_loss / total_samples\n",
    "        wandb.log({\"train_mse\": train_mse})\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train MSE: {train_mse:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        test_loss, total_samples = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            test_pbar = tqdm(test_loader, desc=f\"Epoch {epoch+1} Validation\", leave=False)\n",
    "            for audio_emb, text_emb, labels in test_pbar:\n",
    "                outputs = model(audio_emb, text_emb)\n",
    "                loss = criterion(outputs.squeeze(), labels)\n",
    "                test_loss += loss.item() * audio_emb.size(0)\n",
    "                total_samples += labels.size(0)\n",
    "                test_pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        test_mse = test_loss / total_samples\n",
    "        wandb.log({\"val_mse\": test_mse})\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Val MSE: {test_mse:.4f}\")\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        evaluate(model, test_loader, device)  # Call the evaluation function after each epoch\n",
    "\n",
    "        if test_mse < best_mse:\n",
    "            best_mse = test_mse\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "    print(\"Training complete! Best validation MSE:\", best_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a239c90-a1d1-4757-a3d2-68f3db1d2200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting weak learners...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing embeddings: 100%|████████████████████████████████████████████████████| 3525/3525 [14:28<00:00,  4.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training weak learners...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Ridge Regression: 100%|███████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.09step/s]\n",
      "Training SVR: 100%|████████████████████████████████████████████████████████████████████| 1/1 [01:36<00:00, 96.05s/step]\n",
      "Training Decision Tree: 100%|██████████████████████████████████████████████████████████| 1/1 [00:20<00:00, 20.27s/step]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weak learners training completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train MSE: 7.2800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Val MSE: 5.2919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (±0.5): 0.13%\n",
      "MSE: 5.2919\n",
      "RMSE: 2.3004\n",
      "LCC: 0.2870\n",
      "KTAU: 0.1903\n",
      "\n",
      "5 Examples of Predicted and Ground Truth MOS:\n",
      "Pred: 1.27, GT: 4.00\n",
      "Pred: 1.10, GT: 4.00\n",
      "Pred: 1.27, GT: 3.73\n",
      "Pred: 1.31, GT: 3.40\n",
      "Pred: 0.87, GT: 3.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Train MSE: 3.5679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Val MSE: 2.3683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (±0.5): 4.33%\n",
      "MSE: 2.3683\n",
      "RMSE: 1.5389\n",
      "LCC: 0.3847\n",
      "KTAU: 0.2539\n",
      "\n",
      "5 Examples of Predicted and Ground Truth MOS:\n",
      "Pred: 2.22, GT: 4.00\n",
      "Pred: 2.04, GT: 4.00\n",
      "Pred: 2.18, GT: 3.73\n",
      "Pred: 2.20, GT: 3.40\n",
      "Pred: 1.59, GT: 3.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Train MSE: 1.2882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Val MSE: 0.7816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (±0.5): 31.13%\n",
      "MSE: 0.7816\n",
      "RMSE: 0.8841\n",
      "LCC: 0.4275\n",
      "KTAU: 0.2829\n",
      "\n",
      "5 Examples of Predicted and Ground Truth MOS:\n",
      "Pred: 3.09, GT: 4.00\n",
      "Pred: 2.90, GT: 4.00\n",
      "Pred: 3.03, GT: 3.73\n",
      "Pred: 3.02, GT: 3.40\n",
      "Pred: 2.27, GT: 3.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Train MSE: 0.2497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Val MSE: 0.2926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (±0.5): 63.80%\n",
      "MSE: 0.2926\n",
      "RMSE: 0.5410\n",
      "LCC: 0.4466\n",
      "KTAU: 0.2964\n",
      "\n",
      "5 Examples of Predicted and Ground Truth MOS:\n",
      "Pred: 3.78, GT: 4.00\n",
      "Pred: 3.58, GT: 4.00\n",
      "Pred: 3.69, GT: 3.73\n",
      "Pred: 3.67, GT: 3.40\n",
      "Pred: 2.79, GT: 3.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Train MSE: 0.0437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Val MSE: 0.2783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (±0.5): 65.47%\n",
      "MSE: 0.2783\n",
      "RMSE: 0.5276\n",
      "LCC: 0.4443\n",
      "KTAU: 0.2948\n",
      "\n",
      "5 Examples of Predicted and Ground Truth MOS:\n",
      "Pred: 3.98, GT: 4.00\n",
      "Pred: 3.76, GT: 4.00\n",
      "Pred: 3.89, GT: 3.73\n",
      "Pred: 3.86, GT: 3.40\n",
      "Pred: 2.93, GT: 3.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Train MSE: 0.0361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Val MSE: 0.2857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (±0.5): 65.03%\n",
      "MSE: 0.2857\n",
      "RMSE: 0.5345\n",
      "LCC: 0.4335\n",
      "KTAU: 0.2870\n",
      "\n",
      "5 Examples of Predicted and Ground Truth MOS:\n",
      "Pred: 3.99, GT: 4.00\n",
      "Pred: 3.75, GT: 4.00\n",
      "Pred: 3.90, GT: 3.73\n",
      "Pred: 3.88, GT: 3.40\n",
      "Pred: 2.92, GT: 3.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Train MSE: 0.0327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Val MSE: 0.2939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (±0.5): 64.27%\n",
      "MSE: 0.2939\n",
      "RMSE: 0.5421\n",
      "LCC: 0.4227\n",
      "KTAU: 0.2796\n",
      "\n",
      "5 Examples of Predicted and Ground Truth MOS:\n",
      "Pred: 4.01, GT: 4.00\n",
      "Pred: 3.75, GT: 4.00\n",
      "Pred: 3.92, GT: 3.73\n",
      "Pred: 3.91, GT: 3.40\n",
      "Pred: 2.92, GT: 3.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Train MSE: 0.0290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Val MSE: 0.3021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (±0.5): 63.67%\n",
      "MSE: 0.3021\n",
      "RMSE: 0.5496\n",
      "LCC: 0.4119\n",
      "KTAU: 0.2722\n",
      "\n",
      "5 Examples of Predicted and Ground Truth MOS:\n",
      "Pred: 4.02, GT: 4.00\n",
      "Pred: 3.73, GT: 4.00\n",
      "Pred: 3.94, GT: 3.73\n",
      "Pred: 3.94, GT: 3.40\n",
      "Pred: 2.91, GT: 3.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Train MSE: 0.0270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Val MSE: 0.3106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (±0.5): 62.83%\n",
      "MSE: 0.3106\n",
      "RMSE: 0.5573\n",
      "LCC: 0.4018\n",
      "KTAU: 0.2653\n",
      "\n",
      "5 Examples of Predicted and Ground Truth MOS:\n",
      "Pred: 4.03, GT: 4.00\n",
      "Pred: 3.73, GT: 4.00\n",
      "Pred: 3.96, GT: 3.73\n",
      "Pred: 3.96, GT: 3.40\n",
      "Pred: 2.90, GT: 3.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Train MSE: 0.0235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Val MSE: 0.3198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (±0.5): 62.23%\n",
      "MSE: 0.3198\n",
      "RMSE: 0.5655\n",
      "LCC: 0.3918\n",
      "KTAU: 0.2586\n",
      "\n",
      "5 Examples of Predicted and Ground Truth MOS:\n",
      "Pred: 4.05, GT: 4.00\n",
      "Pred: 3.72, GT: 4.00\n",
      "Pred: 3.98, GT: 3.73\n",
      "Pred: 3.99, GT: 3.40\n",
      "Pred: 2.90, GT: 3.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training:  27%|████████████▍                                 | 954/3525 [04:29<12:15,  3.49it/s, loss=0.00447]"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8be53f-d3ba-4604-a7c2-020dab6cd4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ccbae-827a-46f6-b571-15eb5c400df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d58aa0-3f2d-4dfb-9a98-7f25e8a52fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e3943-87a3-492e-9dbf-a19b8e5b8d39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
