{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f28df6c-fac3-47e8-8457-ee62321f061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from transformers import Wav2Vec2Model, HubertModel, WavLMModel\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import wandb\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb808b6-c3f8-4f50-9319-842844d3cffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12fb6341-8550-49ee-9cbe-7f2c0b53899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = SentenceTransformer(\"all-MiniLM-L6-v2\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a74f2f2-029d-436d-bd96-c8c4795a0dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: rtfiof (rtfiof-hse-university). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>F:\\Project\\att_2\\wandb\\run-20250320_141934-l75fwwc5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rtfiof-hse-university/somos-ensemble2-ssl/runs/l75fwwc5' target=\"_blank\">finetune-only_weak</a></strong> to <a href='https://wandb.ai/rtfiof-hse-university/somos-ensemble2-ssl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rtfiof-hse-university/somos-ensemble2-ssl' target=\"_blank\">https://wandb.ai/rtfiof-hse-university/somos-ensemble2-ssl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rtfiof-hse-university/somos-ensemble2-ssl/runs/l75fwwc5' target=\"_blank\">https://wandb.ai/rtfiof-hse-university/somos-ensemble2-ssl/runs/l75fwwc5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B online. Running your script from this directory will now sync to the cloud.\n"
     ]
    }
   ],
   "source": [
    "# --- Initialize wandb ---\n",
    "wandb.init(project=\"somos-ensemble2-ssl\", name=\"finetune-only_weak\")\n",
    "!wandb online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "302e5bf6-a061-469e-bd72-c1cdae6dafce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Utility Functions ---\n",
    "def load_json(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def process_audio_path(clean_path, base_dir=\"data/somos/audios\"):\n",
    "    return os.path.join(base_dir, clean_path.replace(\"\\\\\", \"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f01dabc-9bf4-4325-92c2-66e2326d6e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dataset Class ---\n",
    "class SOMOSDataset(Dataset):\n",
    "    def __init__(self, json_file, base_dir=\"data/somos/audios\"):\n",
    "        self.samples = load_json(json_file)\n",
    "        self.base_dir = base_dir\n",
    "        self.labels = [float(sample[\"mos\"]) for sample in self.samples]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        text = sample[\"text\"]\n",
    "        label = torch.tensor(float(sample[\"mos\"]), dtype=torch.float)\n",
    "        audio_path = process_audio_path(sample[\"clean path\"], self.base_dir)\n",
    "        return audio_path, text, label\n",
    "\n",
    "def collate_fn(batch):\n",
    "    audio_paths, texts, labels = zip(*batch)\n",
    "    \n",
    "    waveform_list = [torchaudio.load(path)[0] for path in audio_paths]\n",
    "    resample = T.Resample(orig_freq=16000, new_freq=16000)\n",
    "    waveform_list = [resample(waveform) for waveform in waveform_list]\n",
    "\n",
    "    mel_transform = T.MelSpectrogram(sample_rate=16000, n_mels=80)\n",
    "    mel_spectrograms = [mel_transform(waveform).squeeze(0) for waveform in waveform_list]\n",
    "\n",
    "    max_length = max(mel.shape[1] for mel in mel_spectrograms)\n",
    "\n",
    "    def pad_to_max(mel, max_len):\n",
    "        pad_size = max_len - mel.shape[1]\n",
    "        return F.pad(mel, (0, pad_size))\n",
    "\n",
    "    mel_spectrograms = torch.stack([pad_to_max(mel, max_length) for mel in mel_spectrograms]).to(device)\n",
    "\n",
    "    audio_embeddings = mel_spectrograms.mean(dim=-1)\n",
    "    \n",
    "    text_embeddings = text_model.encode(list(texts), convert_to_tensor=True).to(device)\n",
    "\n",
    "    labels = torch.stack(labels).to(device)\n",
    "    return audio_embeddings, text_embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46e84ffc-3b2c-47fd-9c75-6eff75740056",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeakLearners(nn.Module):\n",
    "    def __init__(self, audio_dim, text_dim, device=\"cuda\"):\n",
    "        super(WeakLearners, self).__init__()\n",
    "        self.audio_dim = audio_dim\n",
    "        self.text_dim = text_dim\n",
    "        self.device = device\n",
    "\n",
    "        self.ridge_regressor = Ridge(alpha=1.0)\n",
    "        self.svr = SVR()\n",
    "        self.dtr = DecisionTreeRegressor()\n",
    "\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, train_loader):\n",
    "        \"\"\" Train weak learners using train dataset embeddings \"\"\"\n",
    "        print(\"Fitting weak learners...\")\n",
    "\n",
    "        all_audio_emb, all_text_emb, all_labels = [], [], []\n",
    "\n",
    "        for audio_emb, text_emb, labels in tqdm(train_loader, desc=\"Processing embeddings\", unit=\"batch\"):\n",
    "            all_audio_emb.append(audio_emb.cpu().detach().numpy())\n",
    "            all_text_emb.append(text_emb.cpu().detach().numpy())\n",
    "            all_labels.append(labels.cpu().detach().numpy())\n",
    "\n",
    "        if not all_audio_emb or not all_text_emb or not all_labels:\n",
    "            raise RuntimeError(\"No embeddings found in the dataset! Check if the train_loader is correctly loading data.\")\n",
    "\n",
    "        all_audio_emb = np.vstack(all_audio_emb)\n",
    "        all_text_emb = np.vstack(all_text_emb)\n",
    "        all_labels = np.hstack(all_labels)\n",
    "\n",
    "        combined_embeddings = np.hstack((all_audio_emb, all_text_emb))\n",
    "\n",
    "        print(\"Training weak learners...\")\n",
    "        for model, name in zip([self.ridge_regressor, self.svr, self.dtr], \n",
    "                               [\"Ridge Regression\", \"SVR\", \"Decision Tree\"]):\n",
    "            with tqdm(total=1, desc=f\"Training {name}\", unit=\"step\") as pbar:\n",
    "                model.fit(combined_embeddings, all_labels)\n",
    "                pbar.update(1)\n",
    "\n",
    "        self.fitted = True\n",
    "        print(\"Weak learners training completed.\")\n",
    "\n",
    "    def forward(self, audio_emb, text_emb):\n",
    "        if not self.fitted:\n",
    "            raise RuntimeError(\"Weak learners have not been fitted. Call 'fit()' before using the model.\")\n",
    "\n",
    "        combined_embeddings = torch.cat([audio_emb, text_emb], dim=1).cpu().detach().numpy()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            ridge_pred = self.ridge_regressor.predict(combined_embeddings)\n",
    "            svr_pred = self.svr.predict(combined_embeddings)\n",
    "            dtr_pred = self.dtr.predict(combined_embeddings)\n",
    "\n",
    "        ridge_pred = torch.from_numpy(ridge_pred).float().to(self.device)\n",
    "        svr_pred = torch.from_numpy(svr_pred).float().to(self.device)\n",
    "        dtr_pred = torch.from_numpy(dtr_pred).float().to(self.device)\n",
    "\n",
    "        return ridge_pred, svr_pred, dtr_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ecacc4d-08b4-4ee1-8f43-6ce200e65022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Stacking Model (Meta-Learner) ---\n",
    "class StackingMetaLearner(nn.Module):\n",
    "    def __init__(self, weak_output_dim=3, hidden_dim=256):\n",
    "        super(StackingMetaLearner, self).__init__()\n",
    "        self.fc1 = nn.Linear(weak_output_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, weak_outputs):\n",
    "        x = F.relu(self.fc1(weak_outputs))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "423b5ecb-80b9-4e0c-a10c-86d6f40c5cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Model ---\n",
    "class SSLEnsembleModel(nn.Module):\n",
    "    def __init__(self, audio_dim, text_dim, hidden_dim=256, weak_learners=None):\n",
    "        super(SSLEnsembleModel, self).__init__()\n",
    "        if weak_learners is None:\n",
    "            raise ValueError(\"Weak learners must be provided and fitted before initializing SSLEnsembleModel.\")\n",
    "        \n",
    "        self.weak_learners = weak_learners\n",
    "        self.stacking_meta_learner = StackingMetaLearner(weak_output_dim=3, hidden_dim=hidden_dim)\n",
    "\n",
    "    def forward(self, audio_emb, text_emb):\n",
    "        if not self.weak_learners.fitted:\n",
    "            raise RuntimeError(\"Weak learners have not been fitted. Call 'fit()' before using the model.\")\n",
    "        \n",
    "        ridge_pred, svr_pred, dtr_pred = self.weak_learners(audio_emb, text_emb)\n",
    "\n",
    "        weak_outputs = torch.stack([ridge_pred, svr_pred, dtr_pred], dim=1)\n",
    "\n",
    "        final_output = self.stacking_meta_learner(weak_outputs)\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "246a2b72-6b7c-46d8-b3f5-c50e495e5086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Training Loop ---\n",
    "def main():\n",
    "    train_json = \"data/somos/audios/train_new.json\"\n",
    "    test_json = \"data/somos/audios/test_new.json\"\n",
    "\n",
    "    train_dataset = SOMOSDataset(train_json)\n",
    "    test_dataset = SOMOSDataset(test_json)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    dummy_audio, dummy_text, _ = next(iter(train_loader))\n",
    "    audio_dim, text_dim = dummy_audio.shape[1], dummy_text.shape[1]\n",
    "    \n",
    "    weak_learners = WeakLearners(audio_dim, text_dim).to(device)\n",
    "    weak_learners.fit(train_loader)\n",
    "    \n",
    "    model = SSLEnsembleModel(audio_dim, text_dim, hidden_dim=256, weak_learners=weak_learners).to(device)\n",
    "\n",
    "    wandb.watch(model, log=\"all\", log_freq=100)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    num_epochs = 20\n",
    "    best_mse = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss, total_samples = 0.0, 0\n",
    "\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\", leave=False)\n",
    "        for audio_emb, text_emb, labels in train_pbar:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(audio_emb, text_emb)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * audio_emb.size(0)\n",
    "            total_samples += labels.size(0)\n",
    "            wandb.log({\"train_loss\": loss.item()})\n",
    "            train_pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        train_mse = running_loss / total_samples\n",
    "        wandb.log({\"train_mse\": train_mse})\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train MSE: {train_mse:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        test_loss, total_samples = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            test_pbar = tqdm(test_loader, desc=f\"Epoch {epoch+1} Validation\", leave=False)\n",
    "            for audio_emb, text_emb, labels in test_pbar:\n",
    "                outputs = model(audio_emb, text_emb)\n",
    "                loss = criterion(outputs.squeeze(), labels)\n",
    "                test_loss += loss.item() * audio_emb.size(0)\n",
    "                total_samples += labels.size(0)\n",
    "                test_pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        test_mse = test_loss / total_samples\n",
    "        wandb.log({\"val_mse\": test_mse})\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Val MSE: {test_mse:.4f}\")\n",
    "\n",
    "        if test_mse < best_mse:\n",
    "            best_mse = test_mse\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "    print(\"Training complete! Best validation MSE:\", best_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a239c90-a1d1-4757-a3d2-68f3db1d2200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting weak learners...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing embeddings: 100%|████████████████████████████████████████████████████| 3525/3525 [00:45<00:00, 77.78batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training weak learners...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Ridge Regression: 100%|███████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.75step/s]\n",
      "Training SVR: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:33<00:00, 33.12s/step]\n",
      "Training Decision Tree: 100%|██████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.83s/step]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weak learners training completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train MSE: 22.1980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Val MSE: 18.3550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Train MSE: 15.1797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Val MSE: 12.1435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Train MSE: 9.6047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Val MSE: 7.3068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Train MSE: 5.3898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Val MSE: 3.7940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Train MSE: 2.4978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Val MSE: 1.5721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Train MSE: 0.8698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Val MSE: 0.5328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Train MSE: 0.2958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Val MSE: 0.3256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Train MSE: 0.2292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Val MSE: 0.3221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Train MSE: 0.2307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Val MSE: 0.3230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Train MSE: 0.2301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Val MSE: 0.3239\n",
      "Training complete! Best validation MSE: 0.32213694201037285\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "559f6470-6a9a-444a-b483-c794bf1d53ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting weak learners...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing embeddings: 100%|██████████████████████████████████████████████████████| 750/750 [00:09<00:00, 82.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training weak learners...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Ridge Regression: 100%|███████████████████████████████████████████████████████| 1/1 [00:00<00:00, 70.51step/s]\n",
      "Training SVR: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.79step/s]\n",
      "Training Decision Tree: 100%|██████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.20s/step]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weak learners training completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results:\n",
      "Accuracy (±0.5): 85.00%\n",
      "MSE: 0.1209\n",
      "RMSE: 0.3477\n",
      "LCC: 0.9177\n",
      "Kendall’s Tau: 0.7628\n",
      "\n",
      "Sample Predictions (Predicted MOS vs Ground Truth MOS):\n",
      "Predicted: 3.64 | Ground Truth: 4.00\n",
      "Predicted: 3.58 | Ground Truth: 4.00\n",
      "Predicted: 3.49 | Ground Truth: 3.73\n",
      "Predicted: 3.29 | Ground Truth: 3.40\n",
      "Predicted: 3.07 | Ground Truth: 3.00\n",
      "Predicted: 3.51 | Ground Truth: 3.89\n",
      "Predicted: 3.33 | Ground Truth: 3.33\n",
      "Predicted: 2.97 | Ground Truth: 2.50\n",
      "Predicted: 3.52 | Ground Truth: 3.93\n",
      "Predicted: 3.58 | Ground Truth: 3.90\n",
      "Predicted: 3.52 | Ground Truth: 4.00\n",
      "Predicted: 3.50 | Ground Truth: 3.90\n",
      "Predicted: 3.17 | Ground Truth: 3.00\n",
      "Predicted: 3.35 | Ground Truth: 3.82\n",
      "Predicted: 3.11 | Ground Truth: 2.67\n",
      "Predicted: 3.08 | Ground Truth: 2.75\n",
      "Predicted: 3.33 | Ground Truth: 3.64\n",
      "Predicted: 3.11 | Ground Truth: 2.38\n",
      "Predicted: 3.38 | Ground Truth: 3.56\n",
      "Predicted: 3.47 | Ground Truth: 3.67\n",
      "Predicted: 3.44 | Ground Truth: 3.78\n",
      "Predicted: 3.13 | Ground Truth: 3.00\n",
      "Predicted: 3.39 | Ground Truth: 3.11\n",
      "Predicted: 3.44 | Ground Truth: 3.69\n",
      "Predicted: 3.33 | Ground Truth: 3.20\n",
      "Predicted: 3.60 | Ground Truth: 3.91\n",
      "Predicted: 3.51 | Ground Truth: 3.77\n",
      "Predicted: 3.63 | Ground Truth: 3.89\n",
      "Predicted: 3.44 | Ground Truth: 3.50\n",
      "Predicted: 3.07 | Ground Truth: 2.17\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr, kendalltau\n",
    "\n",
    "def load_model(model_path, audio_dim, text_dim, weak_learners):\n",
    "    model = SSLEnsembleModel(audio_dim, text_dim, hidden_dim=256, weak_learners=weak_learners).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_pbar = tqdm(test_loader, desc=\"Evaluating\", leave=False)\n",
    "        for audio_emb, text_emb, labels in test_pbar:\n",
    "            outputs = model(audio_emb, text_emb)\n",
    "            preds = outputs.squeeze().cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    mse = np.mean((all_preds - all_labels) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    lcc, _ = pearsonr(all_preds, all_labels)\n",
    "    ktau, _ = kendalltau(all_preds, all_labels)\n",
    "\n",
    "    accuracy = np.mean(np.abs(all_preds - all_labels) <= 0.5)\n",
    "\n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    print(f\"Accuracy (±0.5): {accuracy * 100:.2f}%\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"LCC: {lcc:.4f}\")\n",
    "    print(f\"Kendall’s Tau: {ktau:.4f}\\n\")\n",
    "\n",
    "    print(\"Sample Predictions (Predicted MOS vs Ground Truth MOS):\")\n",
    "    for i in range(min(30, len(all_preds))):\n",
    "        print(f\"Predicted: {all_preds[i]:.2f} | Ground Truth: {all_labels[i]:.2f}\")\n",
    "\n",
    "test_json = \"data/somos/audios/test_new.json\"\n",
    "test_dataset = SOMOSDataset(test_json)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "dummy_audio, dummy_text, _ = next(iter(test_loader))\n",
    "audio_dim, text_dim = dummy_audio.shape[1], dummy_text.shape[1]\n",
    "\n",
    "weak_learners = WeakLearners(audio_dim, text_dim).to(device)\n",
    "weak_learners.fit(test_loader)\n",
    "\n",
    "model = load_model(\"best_model.pth\", audio_dim, text_dim, weak_learners)\n",
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8be53f-d3ba-4604-a7c2-020dab6cd4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ccbae-827a-46f6-b571-15eb5c400df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d58aa0-3f2d-4dfb-9a98-7f25e8a52fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e3943-87a3-492e-9dbf-a19b8e5b8d39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
