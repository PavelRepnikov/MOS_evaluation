{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b58a0de-b6d1-4a33-8894-74b7b33e5a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import whisper\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aca257b-7570-428d-a0fe-510febdb9727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: rtfiof (rtfiof-hse-university). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>F:\\Project\\att_2\\wandb\\run-20250316_102611-tpukis5r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rtfiof-hse-university/somos-ensemble-cont/runs/tpukis5r' target=\"_blank\">finetune-whisper-ensemble</a></strong> to <a href='https://wandb.ai/rtfiof-hse-university/somos-ensemble-cont' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rtfiof-hse-university/somos-ensemble-cont' target=\"_blank\">https://wandb.ai/rtfiof-hse-university/somos-ensemble-cont</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rtfiof-hse-university/somos-ensemble-cont/runs/tpukis5r' target=\"_blank\">https://wandb.ai/rtfiof-hse-university/somos-ensemble-cont/runs/tpukis5r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B online. Running your script from this directory will now sync to the cloud.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread IntMsgThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 325, in check_internal_messages\n",
      "    self._loop_check_status(\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 235, in _loop_check_status\n",
      "    local_handle = request()\n",
      "                   ^^^^^^^^^\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\wandb\\sdk\\interface\\interface.py\", line 914, in deliver_internal_messages\n",
      "    return self._deliver_internal_messages(internal_message)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 503, in _deliver_internal_messages\n",
      "    return self._deliver_record(record)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 452, in _deliver_record\n",
      "    handle = mailbox._deliver_record(record, interface=self)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\wandb\\sdk\\lib\\mailbox.py\", line 451, in _deliver_record\n",
      "    interface._publish(record)\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 222, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 154, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 151, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Exception in thread ChkStopThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 305, in check_stop_status\n",
      "    self._loop_check_status(\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 235, in _loop_check_status\n",
      "    local_handle = request()\n",
      "                   ^^^^^^^^^\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\wandb\\sdk\\interface\\interface.py\", line 898, in deliver_stop_status\n",
      "    return self._deliver_stop_status(status)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 487, in _deliver_stop_status\n",
      "    return self._deliver_record(record)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 452, in _deliver_record\n",
      "    handle = mailbox._deliver_record(record, interface=self)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\wandb\\sdk\\lib\\mailbox.py\", line 451, in _deliver_record\n",
      "    interface._publish(record)\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 222, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 154, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 151, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"D:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Load and Unfreeze Whisperâ€‘medium ---\n",
    "whisper_model = whisper.load_model(\"base.en\").to(device)\n",
    "# Unfreeze all layers in Whisper\n",
    "for param in whisper_model.parameters():\n",
    "    param.requires_grad = True\n",
    "whisper_model.train()  # Set to train mode so gradients are computed\n",
    "\n",
    "# Load BERT tokenizer and model (BERT remains frozen here).\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\").to(device).eval()\n",
    "\n",
    "# --- Initialize wandb ---\n",
    "wandb.init(project=\"somos-ensemble-cont\", name=\"finetune-whisper-ensemble\")\n",
    "!wandb online\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81956502-241c-4732-8880-36f7a46062a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc2e5acf-9c33-4ef7-b17c-ad8077f16d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Utility Functions ---\n",
    "\n",
    "# Function to compute class weights\n",
    "# Compute class weights for imbalanced dataset\n",
    "def compute_class_weights(labels, num_bins=5):\n",
    "    # Quantize the MOS labels into bins\n",
    "    min_mos = min(labels)\n",
    "    max_mos = max(labels)\n",
    "    bin_width = (max_mos - min_mos) / num_bins\n",
    "    bins = [min_mos + i * bin_width for i in range(num_bins + 1)]\n",
    "    \n",
    "    # Assign each MOS value to a bin\n",
    "    bin_indices = [min(int((mos - min_mos) / bin_width), num_bins - 1) for mos in labels]\n",
    "    \n",
    "    # Initialize class counts for all bins (even if a bin has no samples)\n",
    "    class_counts = {i: 0 for i in range(num_bins)}\n",
    "    for bin_idx in bin_indices:\n",
    "        class_counts[bin_idx] += 1\n",
    "\n",
    "    total_samples = sum(class_counts.values())\n",
    "    weights = {cls: total_samples / (num_bins * count) for cls, count in class_counts.items()}\n",
    "\n",
    "    # Ensure all bins are represented in the weights\n",
    "    return torch.tensor([weights.get(i, 0) for i in range(num_bins)], dtype=torch.float).to(device)\n",
    "\n",
    "\n",
    "\n",
    "# Function to compute sample weights for oversampling\n",
    "def get_sample_weights(dataset, class_weights):\n",
    "    sample_weights = []\n",
    "\n",
    "    for _, _, label in dataset:\n",
    "        sample_weights.append(class_weights[label].item())\n",
    "\n",
    "    return torch.tensor(sample_weights, dtype=torch.float)\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def process_audio_path(clean_path, base_dir=\"data/somos/audios\"):\n",
    "    return os.path.join(base_dir, clean_path.replace(\"\\\\\", \"/\"))\n",
    "\n",
    "# Earth Moverâ€™s Distance (EMD) Loss for ordinal MOS prediction.\n",
    "def emd_loss(y_pred, y_true, num_classes):\n",
    "    y_pred = F.softmax(y_pred, dim=-1)  # Convert logits to probability distribution\n",
    "    y_true = F.one_hot(y_true, num_classes).float()  # Convert labels to one-hot\n",
    "\n",
    "    cdf_pred = torch.cumsum(y_pred, dim=-1)  # Compute cumulative sum for predicted distribution\n",
    "    cdf_true = torch.cumsum(y_true, dim=-1)  # Compute cumulative sum for true distribution\n",
    "\n",
    "    loss = torch.mean((cdf_pred - cdf_true) ** 2)  # Use squared difference for smoother gradients\n",
    "    return loss\n",
    "\n",
    "def entropy_regularization(gate_weights, lambda_reg=0.01):\n",
    "    # Compute entropy loss to encourage diverse gating weights\n",
    "    eps = 1e-8\n",
    "    entropy = -torch.sum(gate_weights * torch.log(gate_weights + eps), dim=1)\n",
    "    return lambda_reg * torch.mean(entropy)\n",
    "\n",
    "def save_model(model, epoch, best_acc, save_path=\"models\"):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    model_path = os.path.join(save_path, f\"model_epoch_{epoch}.pth\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    best_model_path = os.path.join(save_path, \"best_model.pth\")\n",
    "    if best_acc:\n",
    "        torch.save(model.state_dict(), best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af3dd2f7-e672-4380-a5f6-e77503c8f2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dataset Class ---\n",
    "class SOMOSDataset(Dataset):\n",
    "    def __init__(self, json_file, base_dir=\"data/somos/audios\"):\n",
    "        self.samples = load_json(json_file)\n",
    "        self.base_dir = base_dir\n",
    "        # Store MOS as float for continuous values (not just integer)\n",
    "        self.labels = [float(sample[\"mos\"]) for sample in self.samples]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        text = sample[\"text\"]\n",
    "        label = torch.tensor(float(sample[\"mos\"]), dtype=torch.float)\n",
    "        audio_path = process_audio_path(sample[\"clean path\"], self.base_dir)\n",
    "        return audio_path, text, label\n",
    "\n",
    "def collate_fn(batch):\n",
    "    audio_paths, texts, labels = zip(*batch)\n",
    "    audios = [whisper.load_audio(path) for path in audio_paths]\n",
    "    audios = [whisper.pad_or_trim(audio) for audio in audios]\n",
    "    mel_spectrograms = [whisper.log_mel_spectrogram(audio).to(device) for audio in audios]\n",
    "    mel_spectrograms = torch.stack(mel_spectrograms)\n",
    "\n",
    "    # Compute audio embeddings with gradients enabled\n",
    "    audio_embeddings = whisper_model.encoder(mel_spectrograms).mean(dim=1)\n",
    "\n",
    "    # Process texts using BERT (BERT remains frozen)\n",
    "    inputs = tokenizer(list(texts), return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        text_embeddings = bert_model(**inputs).last_hidden_state[:, 0, :]\n",
    "\n",
    "    labels = torch.stack(labels).to(device)\n",
    "    return audio_embeddings, text_embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d58b1a0-0814-4f13-8671-c8ac126117d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexFusionSubModel(nn.Module):\n",
    "    def __init__(self, audio_dim, text_dim, hidden_dim, dropout_rate=0.05):\n",
    "        super(ComplexFusionSubModel, self).__init__()\n",
    "        self.audio_fc = nn.Sequential(\n",
    "            nn.Linear(audio_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "        )\n",
    "        self.text_fc = nn.Sequential(\n",
    "            nn.Linear(text_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "        )\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        # Output layer changed to produce a single value for continuous prediction\n",
    "        self.fusion_fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1)  # Output a single value (regression)\n",
    "        )\n",
    "\n",
    "    def forward(self, audio_emb, text_emb):\n",
    "        audio_feat = self.audio_fc(audio_emb)\n",
    "        text_feat = self.text_fc(text_emb)\n",
    "        fusion = torch.cat([audio_feat, text_feat], dim=1)\n",
    "        attn_weights = self.attention(fusion)\n",
    "        fusion = fusion * attn_weights\n",
    "        return self.fusion_fc(fusion)  # Output a single value for regression\n",
    "\n",
    "\n",
    "class EnsembleFusionClassifier(nn.Module):\n",
    "    def __init__(self, audio_dim, text_dim, hidden_dim, dropout_rate=0.05, num_models=3):\n",
    "        super(EnsembleFusionClassifier, self).__init__()\n",
    "        self.num_models = num_models\n",
    "        self.sub_models = nn.ModuleList([\n",
    "            ComplexFusionSubModel(audio_dim, text_dim, hidden_dim, dropout_rate)\n",
    "            for _ in range(num_models)\n",
    "        ])\n",
    "        # Gate mechanism for selecting the weighted output from each model\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(audio_dim + text_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_models),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        # Residual connection (optional)\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Linear(1, 1),  # Output a single value for regression\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, audio_emb, text_emb, return_gate=False):\n",
    "        gate_input = torch.cat([audio_emb, text_emb], dim=1)\n",
    "        gate_weights = self.gate(gate_input)  # (batch_size, num_models)\n",
    "        outputs = [model(audio_emb, text_emb) for model in self.sub_models]\n",
    "        outputs = torch.stack(outputs, dim=1)  # (batch_size, num_models, 1)\n",
    "        gate_weights_unsq = gate_weights.unsqueeze(2)  # (batch_size, num_models, 1)\n",
    "        ensemble_output = (gate_weights_unsq * outputs).sum(dim=1)  # Weighted sum of model outputs\n",
    "        final_output = ensemble_output + self.residual(ensemble_output)  # Apply residual\n",
    "        if return_gate:\n",
    "            return final_output, gate_weights\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36a118a2-3e4c-4b58-99ad-166cc2f9b4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_json = \"data/somos/audios/train_new.json\"\n",
    "    test_json = \"data/somos/audios/test_new.json\"\n",
    "\n",
    "    # Load datasets\n",
    "    train_dataset = SOMOSDataset(train_json)\n",
    "    test_dataset = SOMOSDataset(test_json)\n",
    "\n",
    "    # Compute sample weights based on MOS values\n",
    "    class_weights = compute_class_weights(train_dataset.labels, num_bins=5)\n",
    "    sample_weights = [class_weights[min(int(mos), 4)].item() for mos in train_dataset.labels]  # Quantizing MOS values\n",
    "    sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "\n",
    "    # Create DataLoader with sampling\n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, sampler=sampler, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    # Check dimensions of a sample batch to set input dimensions for the model\n",
    "    dummy_audio, dummy_text, _ = next(iter(train_loader))\n",
    "    audio_dim, text_dim = dummy_audio.shape[1], dummy_text.shape[1]\n",
    "\n",
    "    # Define the number of classes (regression task, not used directly in the model)\n",
    "    num_classes = 1  # For continuous MOS prediction, there is only one output value per sample\n",
    "\n",
    "    # Instantiate the ensemble classifier model\n",
    "    model = EnsembleFusionClassifier(audio_dim, text_dim, hidden_dim=256, dropout_rate=0.05, num_models=3).to(device)\n",
    "\n",
    "    # Watch the model with WandB for logging gradients and parameters\n",
    "    wandb.watch(model, log=\"all\", log_freq=100)\n",
    "\n",
    "    # Set up gradient scaler for mixed precision training\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    # Define MSE loss for continuous MOS prediction\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Set up optimizer (Adam with a very small learning rate)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "    num_epochs = 100\n",
    "    best_mse = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss, total_samples = 0.0, 0\n",
    "\n",
    "        # Training loop with progress bar\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\", leave=False)\n",
    "        for audio_emb, text_emb, labels in train_pbar:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Perform forward pass with mixed precision\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs, gate_weights = model(audio_emb, text_emb, return_gate=True)\n",
    "\n",
    "                # Ensure the output shape matches that of labels (i.e., batch_size, 1)\n",
    "                outputs = outputs.squeeze()  # Remove unnecessary dimensions\n",
    "                labels = labels.squeeze()    # Ensure labels are in the correct shape\n",
    "\n",
    "                # Check if shapes match before computing loss\n",
    "                assert outputs.shape == labels.shape, f\"Shape mismatch: {outputs.shape} vs {labels.shape}\"\n",
    "\n",
    "                # Calculate loss using MSE\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass with gradient scaling for mixed precision\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # Clip gradients to prevent exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # Accumulate loss for logging\n",
    "            running_loss += loss.item() * audio_emb.size(0)\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            # Log the training loss with WandB\n",
    "            wandb.log({\n",
    "                \"train_loss\": loss.item(),\n",
    "            })\n",
    "            train_pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        # Calculate and log training MSE\n",
    "        train_mse = running_loss / total_samples\n",
    "        wandb.log({\"train_mse\": train_mse})\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train MSE: {train_mse:.4f}\")\n",
    "\n",
    "        # Evaluation phase\n",
    "        model.eval()\n",
    "        test_loss, total_samples = 0.0, 0\n",
    "        test_predictions = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Testing loop with progress bar\n",
    "            test_pbar = tqdm(test_loader, desc=f\"Epoch {epoch+1} Validation\", leave=False)\n",
    "            for audio_emb, text_emb, labels in test_pbar:\n",
    "                audio_emb = audio_emb.to(device)\n",
    "                text_emb = text_emb.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Get model predictions\n",
    "                outputs = model(audio_emb, text_emb)\n",
    "\n",
    "                # Ensure output and labels are in compatible shapes\n",
    "                outputs = outputs.squeeze()\n",
    "                labels = labels.squeeze()\n",
    "\n",
    "                # Calculate test loss\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                test_loss += loss.item() * audio_emb.size(0)\n",
    "                total_samples += labels.size(0)\n",
    "                test_predictions.extend(zip(labels.cpu().tolist(), outputs.cpu().tolist()))\n",
    "                test_pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        # Calculate and log test MSE\n",
    "        test_mse = test_loss / total_samples\n",
    "        wandb.log({\"val_mse\": test_mse})\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Val MSE: {test_mse:.4f}\")\n",
    "\n",
    "        # Log some sample predictions\n",
    "        print(\"\\nSample Predictions (Real MOS vs Predicted MOS):\")\n",
    "        for i, (real_mos, pred_mos) in enumerate(test_predictions[:5]):\n",
    "            print(f\"Example {i+1}: Real MOS = {real_mos}, Predicted MOS = {pred_mos}\")\n",
    "            wandb.log({f\"sample_{i}_real_vs_pred\": f\"{real_mos} vs {pred_mos}\"})\n",
    "        \n",
    "        # Save the model if the validation MSE improves\n",
    "        save_model(model, epoch + 1, test_mse < best_mse)\n",
    "\n",
    "        if test_mse < best_mse:\n",
    "            best_mse = test_mse\n",
    "\n",
    "    print(\"Training complete! Best validation MSE:\", best_mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6da0ed7-7510-44f7-a47f-e2c76c940059",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q\\AppData\\Local\\Temp\\ipykernel_16452\\3654406737.py:32: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "Epoch 1 Training:   0%|                                                                       | 0/3525 [00:00<?, ?it/s]C:\\Users\\q\\AppData\\Local\\Temp\\ipykernel_16452\\3654406737.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Train MSE: 8.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Val MSE: 4.6508\n",
      "\n",
      "Sample Predictions (Real MOS vs Predicted MOS):\n",
      "Example 1: Real MOS = 4.0, Predicted MOS = 1.1607378721237183\n",
      "Example 2: Real MOS = 4.0, Predicted MOS = 0.812701940536499\n",
      "Example 3: Real MOS = 3.7272727489471436, Predicted MOS = 1.5484755039215088\n",
      "Example 4: Real MOS = 3.4000000953674316, Predicted MOS = 1.0674092769622803\n",
      "Example 5: Real MOS = 3.0, Predicted MOS = 1.4412553310394287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 - Train MSE: 6.5422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 - Val MSE: 3.5313\n",
      "\n",
      "Sample Predictions (Real MOS vs Predicted MOS):\n",
      "Example 1: Real MOS = 4.0, Predicted MOS = 1.498292088508606\n",
      "Example 2: Real MOS = 4.0, Predicted MOS = 1.0315018892288208\n",
      "Example 3: Real MOS = 3.7272727489471436, Predicted MOS = 1.9982125759124756\n",
      "Example 4: Real MOS = 3.4000000953674316, Predicted MOS = 1.2436354160308838\n",
      "Example 5: Real MOS = 3.0, Predicted MOS = 1.9349894523620605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 - Train MSE: 5.8053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 - Val MSE: 3.0452\n",
      "\n",
      "Sample Predictions (Real MOS vs Predicted MOS):\n",
      "Example 1: Real MOS = 4.0, Predicted MOS = 1.2202459573745728\n",
      "Example 2: Real MOS = 4.0, Predicted MOS = 0.9924641251564026\n",
      "Example 3: Real MOS = 3.7272727489471436, Predicted MOS = 2.1842806339263916\n",
      "Example 4: Real MOS = 3.4000000953674316, Predicted MOS = 0.9821459650993347\n",
      "Example 5: Real MOS = 3.0, Predicted MOS = 1.9845068454742432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 - Train MSE: 5.0929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 - Val MSE: 2.4831\n",
      "\n",
      "Sample Predictions (Real MOS vs Predicted MOS):\n",
      "Example 1: Real MOS = 4.0, Predicted MOS = 1.469470739364624\n",
      "Example 2: Real MOS = 4.0, Predicted MOS = 1.3966904878616333\n",
      "Example 3: Real MOS = 3.7272727489471436, Predicted MOS = 2.4737887382507324\n",
      "Example 4: Real MOS = 3.4000000953674316, Predicted MOS = 2.0226187705993652\n",
      "Example 5: Real MOS = 3.0, Predicted MOS = 2.45470929145813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 - Train MSE: 4.4326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 - Val MSE: 1.6155\n",
      "\n",
      "Sample Predictions (Real MOS vs Predicted MOS):\n",
      "Example 1: Real MOS = 4.0, Predicted MOS = 1.704763412475586\n",
      "Example 2: Real MOS = 4.0, Predicted MOS = 1.3491932153701782\n",
      "Example 3: Real MOS = 3.7272727489471436, Predicted MOS = 3.065774440765381\n",
      "Example 4: Real MOS = 3.4000000953674316, Predicted MOS = 2.154963254928589\n",
      "Example 5: Real MOS = 3.0, Predicted MOS = 2.7340755462646484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 - Train MSE: 3.8446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 - Val MSE: 1.5237\n",
      "\n",
      "Sample Predictions (Real MOS vs Predicted MOS):\n",
      "Example 1: Real MOS = 4.0, Predicted MOS = 2.044430732727051\n",
      "Example 2: Real MOS = 4.0, Predicted MOS = 1.816087245941162\n",
      "Example 3: Real MOS = 3.7272727489471436, Predicted MOS = 2.8972599506378174\n",
      "Example 4: Real MOS = 3.4000000953674316, Predicted MOS = 1.826528549194336\n",
      "Example 5: Real MOS = 3.0, Predicted MOS = 2.3948299884796143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 - Train MSE: 3.3145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 - Val MSE: 0.9354\n",
      "\n",
      "Sample Predictions (Real MOS vs Predicted MOS):\n",
      "Example 1: Real MOS = 4.0, Predicted MOS = 2.5917716026306152\n",
      "Example 2: Real MOS = 4.0, Predicted MOS = 1.9791901111602783\n",
      "Example 3: Real MOS = 3.7272727489471436, Predicted MOS = 3.836705207824707\n",
      "Example 4: Real MOS = 3.4000000953674316, Predicted MOS = 2.5647761821746826\n",
      "Example 5: Real MOS = 3.0, Predicted MOS = 2.9043021202087402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 - Train MSE: 2.8326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 - Val MSE: 0.9942\n",
      "\n",
      "Sample Predictions (Real MOS vs Predicted MOS):\n",
      "Example 1: Real MOS = 4.0, Predicted MOS = 2.3691368103027344\n",
      "Example 2: Real MOS = 4.0, Predicted MOS = 2.1023480892181396\n",
      "Example 3: Real MOS = 3.7272727489471436, Predicted MOS = 3.1004490852355957\n",
      "Example 4: Real MOS = 3.4000000953674316, Predicted MOS = 2.516868829727173\n",
      "Example 5: Real MOS = 3.0, Predicted MOS = 2.7788374423980713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 - Train MSE: 2.3719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 - Val MSE: 0.8433\n",
      "\n",
      "Sample Predictions (Real MOS vs Predicted MOS):\n",
      "Example 1: Real MOS = 4.0, Predicted MOS = 2.241647720336914\n",
      "Example 2: Real MOS = 4.0, Predicted MOS = 2.100292682647705\n",
      "Example 3: Real MOS = 3.7272727489471436, Predicted MOS = 3.3095879554748535\n",
      "Example 4: Real MOS = 3.4000000953674316, Predicted MOS = 2.4926095008850098\n",
      "Example 5: Real MOS = 3.0, Predicted MOS = 2.8073229789733887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 - Train MSE: 1.9902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 - Val MSE: 0.6261\n",
      "\n",
      "Sample Predictions (Real MOS vs Predicted MOS):\n",
      "Example 1: Real MOS = 4.0, Predicted MOS = 2.3074164390563965\n",
      "Example 2: Real MOS = 4.0, Predicted MOS = 2.192262887954712\n",
      "Example 3: Real MOS = 3.7272727489471436, Predicted MOS = 3.962413787841797\n",
      "Example 4: Real MOS = 3.4000000953674316, Predicted MOS = 2.6482346057891846\n",
      "Example 5: Real MOS = 3.0, Predicted MOS = 3.1650524139404297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 - Train MSE: 1.6175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 - Val MSE: 0.5068\n",
      "\n",
      "Sample Predictions (Real MOS vs Predicted MOS):\n",
      "Example 1: Real MOS = 4.0, Predicted MOS = 2.938669204711914\n",
      "Example 2: Real MOS = 4.0, Predicted MOS = 2.7256152629852295\n",
      "Example 3: Real MOS = 3.7272727489471436, Predicted MOS = 3.762974739074707\n",
      "Example 4: Real MOS = 3.4000000953674316, Predicted MOS = 3.1050310134887695\n",
      "Example 5: Real MOS = 3.0, Predicted MOS = 3.3691601753234863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 - Train MSE: 1.3780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 - Val MSE: 0.4714\n",
      "\n",
      "Sample Predictions (Real MOS vs Predicted MOS):\n",
      "Example 1: Real MOS = 4.0, Predicted MOS = 3.5616965293884277\n",
      "Example 2: Real MOS = 4.0, Predicted MOS = 3.119319200515747\n",
      "Example 3: Real MOS = 3.7272727489471436, Predicted MOS = 4.048720359802246\n",
      "Example 4: Real MOS = 3.4000000953674316, Predicted MOS = 3.1989569664001465\n",
      "Example 5: Real MOS = 3.0, Predicted MOS = 3.560316562652588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 - Train MSE: 1.1518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 - Val MSE: 0.4712\n",
      "\n",
      "Sample Predictions (Real MOS vs Predicted MOS):\n",
      "Example 1: Real MOS = 4.0, Predicted MOS = 2.660867929458618\n",
      "Example 2: Real MOS = 4.0, Predicted MOS = 2.4787795543670654\n",
      "Example 3: Real MOS = 3.7272727489471436, Predicted MOS = 4.129580497741699\n",
      "Example 4: Real MOS = 3.4000000953674316, Predicted MOS = 3.285508632659912\n",
      "Example 5: Real MOS = 3.0, Predicted MOS = 3.584831714630127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 - Train MSE: 0.9760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 - Val MSE: 1.0157\n",
      "\n",
      "Sample Predictions (Real MOS vs Predicted MOS):\n",
      "Example 1: Real MOS = 4.0, Predicted MOS = 3.4898438453674316\n",
      "Example 2: Real MOS = 4.0, Predicted MOS = 2.904170513153076\n",
      "Example 3: Real MOS = 3.7272727489471436, Predicted MOS = 4.8024468421936035\n",
      "Example 4: Real MOS = 3.4000000953674316, Predicted MOS = 3.456948757171631\n",
      "Example 5: Real MOS = 3.0, Predicted MOS = 4.263199806213379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 - Train MSE: 0.8184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 - Val MSE: 0.4823\n",
      "\n",
      "Sample Predictions (Real MOS vs Predicted MOS):\n",
      "Example 1: Real MOS = 4.0, Predicted MOS = 3.295330047607422\n",
      "Example 2: Real MOS = 4.0, Predicted MOS = 3.0825064182281494\n",
      "Example 3: Real MOS = 3.7272727489471436, Predicted MOS = 3.9900503158569336\n",
      "Example 4: Real MOS = 3.4000000953674316, Predicted MOS = 3.3038344383239746\n",
      "Example 5: Real MOS = 3.0, Predicted MOS = 3.5901551246643066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 - Train MSE: 0.7130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 - Val MSE: 0.8254\n",
      "\n",
      "Sample Predictions (Real MOS vs Predicted MOS):\n",
      "Example 1: Real MOS = 4.0, Predicted MOS = 3.533033847808838\n",
      "Example 2: Real MOS = 4.0, Predicted MOS = 3.09549880027771\n",
      "Example 3: Real MOS = 3.7272727489471436, Predicted MOS = 4.650455474853516\n",
      "Example 4: Real MOS = 3.4000000953674316, Predicted MOS = 3.6377463340759277\n",
      "Example 5: Real MOS = 3.0, Predicted MOS = 4.042354106903076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 - Train MSE: 0.6533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 - Val MSE: 0.7455\n",
      "\n",
      "Sample Predictions (Real MOS vs Predicted MOS):\n",
      "Example 1: Real MOS = 4.0, Predicted MOS = 3.6503710746765137\n",
      "Example 2: Real MOS = 4.0, Predicted MOS = 3.3007984161376953\n",
      "Example 3: Real MOS = 3.7272727489471436, Predicted MOS = 4.227035045623779\n",
      "Example 4: Real MOS = 3.4000000953674316, Predicted MOS = 4.156992435455322\n",
      "Example 5: Real MOS = 3.0, Predicted MOS = 4.3412041664123535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 - Train MSE: 0.6363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 - Val MSE: 0.5508\n",
      "\n",
      "Sample Predictions (Real MOS vs Predicted MOS):\n",
      "Example 1: Real MOS = 4.0, Predicted MOS = 3.5612688064575195\n",
      "Example 2: Real MOS = 4.0, Predicted MOS = 3.291835069656372\n",
      "Example 3: Real MOS = 3.7272727489471436, Predicted MOS = 4.135792255401611\n",
      "Example 4: Real MOS = 3.4000000953674316, Predicted MOS = 3.5392203330993652\n",
      "Example 5: Real MOS = 3.0, Predicted MOS = 3.681854248046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 - Train MSE: 0.6009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 - Val MSE: 0.9191\n",
      "\n",
      "Sample Predictions (Real MOS vs Predicted MOS):\n",
      "Example 1: Real MOS = 4.0, Predicted MOS = 3.679015636444092\n",
      "Example 2: Real MOS = 4.0, Predicted MOS = 3.241779327392578\n",
      "Example 3: Real MOS = 3.7272727489471436, Predicted MOS = 4.674153804779053\n",
      "Example 4: Real MOS = 3.4000000953674316, Predicted MOS = 4.13768196105957\n",
      "Example 5: Real MOS = 3.0, Predicted MOS = 4.338153839111328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 - Train MSE: 0.5883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 - Val MSE: 0.6792\n",
      "\n",
      "Sample Predictions (Real MOS vs Predicted MOS):\n",
      "Example 1: Real MOS = 4.0, Predicted MOS = 3.593503475189209\n",
      "Example 2: Real MOS = 4.0, Predicted MOS = 3.3273098468780518\n",
      "Example 3: Real MOS = 3.7272727489471436, Predicted MOS = 4.278740882873535\n",
      "Example 4: Real MOS = 3.4000000953674316, Predicted MOS = 3.652090549468994\n",
      "Example 5: Real MOS = 3.0, Predicted MOS = 3.88718843460083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 - Train MSE: 0.5849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 - Val MSE: 0.4601\n",
      "\n",
      "Sample Predictions (Real MOS vs Predicted MOS):\n",
      "Example 1: Real MOS = 4.0, Predicted MOS = 3.368781089782715\n",
      "Example 2: Real MOS = 4.0, Predicted MOS = 3.249788999557495\n",
      "Example 3: Real MOS = 3.7272727489471436, Predicted MOS = 3.8168792724609375\n",
      "Example 4: Real MOS = 3.4000000953674316, Predicted MOS = 3.55024790763855\n",
      "Example 5: Real MOS = 3.0, Predicted MOS = 3.6338706016540527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 71\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Clip gradients to prevent exploding gradients\u001b[39;00m\n\u001b[0;32m     70\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m---> 71\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Accumulate loss for logging\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:457\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    455\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 457\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:351\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda\\envs\\project\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:351\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256d51b6-5c6c-44a5-b7d6-62b128f7967a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be734f84-09c9-4e5f-bfdb-1d6554af566a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fde0f3-d393-43ca-88f8-f200f8470521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c550aef6-da08-4264-a5a0-4170d3136b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7529c700-af68-4abb-ba14-61c4e877fb83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a11d9-59e3-40e4-a16b-bfc5ad993fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
